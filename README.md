# Neural Networks from Scratch
Implementing Artificial Neural Network from scratch using C++

There are two implementations listed here:
1) A [basic_ann](https://github.com/codebuddha/Neural_Networks_from_Scratch/blob/master/basic_ann.cpp) without using any libraries, just raw C++. The [main](https://github.com/codebuddha/Neural_Networks_from_Scratch/blob/55c7b0e9a8a3571a726ab744151ba351a4840dfb/basic_ann.cpp#L191) function here is to train the network to act as a 3-input XOR operator.

2) A vectorized implementation of an ANN (include [this header](https://github.com/codebuddha/Neural_Networks_from_Scratch/blob/master/AF_ANN.hpp)) using the [ArrayFire](http://arrayfire.org/docs/index.htm) library that allows the use of an unified source-code to compile programs for CPU, CUDA, as well as OpenCL. Some features that allow for smooth experimentation:
    - Ability to add custom activation functions using the [`Layer::setNewActivation`](https://github.com/codebuddha/Neural_Networks_from_Scratch/blob/1255ffddde497e32aaf9e673e8ea6e3493b8a368/Layer.hpp#L65) function, as shown [here](https://github.com/codebuddha/Neural_Networks_from_Scratch/blob/1255ffddde497e32aaf9e673e8ea6e3493b8a368/custom_activation.cpp#L32). 
    - Decaying learning rate across epochs as shown [here](https://github.com/codebuddha/Neural_Networks_from_Scratch/blob/32953bff3d381d9383793a9bca816362f61f1af1/test_XOR.cpp#L58), by defining a custom [`calc_LRdecay`](https://github.com/codebuddha/Neural_Networks_from_Scratch/blob/32953bff3d381d9383793a9bca816362f61f1af1/test_XOR.cpp#L16) function.
Implementation of [XOR](https://github.com/codebuddha/Neural_Networks_from_Scratch/blob/master/test_XOR.cpphttps://github.com/codebuddha/Neural_Networks_from_Scratch/blob/master/test_XOR_training.txt) with [loss-values]().